# 2025-10-27 

straight states - pos+neg global feedback propagation 
np.mean([-4.0, -4.0, -3.0, -4.0, -3.0, -3.0, -3.0, -5.0, -3.0, -5.0, -3.0, -5.0, -4.0, -4.0, -4.0, -3.0, -5.0, -3.0, -4.0, -5.0, -5.0, -5.0, -4.0, -4.0, -4.0, -3.0, -5.0, -5.0, -1.0, -5.0, -5.0, -4.0, -5.0, -4.0, -4.0, -5.0, -5.0, -5.0, -5.0, -4.0, -5.0, -3.0, -5.0, -5.0, -5.0, -4.0, -4.0, -4.0, -3.0, -5.0, -5.0, -1.0, -5.0, -5.0, -4.0, -5.0, -4.0, -4.0, -5.0, -5.0, -5.0, -5.0, -4.0, -5.0, -3.0, -5.0, -5.0, -5.0, -4.0, -4.0, -4.0, -3.0, -5.0, -5.0, -1.0, -5.0, -5.0, -4.0, -5.0, -4.0, -4.0, -5.0, -5.0, -5.0, -5.0, -4.0, -5.0, -3.0, -5.0, -5.0, -5.0, -4.0, -4.0, -4.0, -3.0, -5.0, -5.0, -1.0, -5.0, -5.0, -4.0, -5.0, -4.0, -4.0, -5.0, -5.0, -5.0, -5.0, -4.0, -5.0, -3.0, -5.0, -5.0, -5.0, -4.0, -4.0, -4.0, -3.0, -5.0, -5.0, -1.0, -5.0, -5.0, -4.0, -5.0, -4.0, -4.0, -5.0, -5.0, -5.0, -5.0, -4.0, -4.0, -3.0, -4.0, -5.0, -4.0, -5.0, -5.0, -5.0, -5.0, -5.0, -4.0, -4.0, -4.0, -3.0, -5.0, -3.0, -3.0, -5.0, -5.0, -4.0, -5.0, -5.0, -5.0, -4.0, -4.0, -3.0, -4.0, -5.0, -3.0, -5.0, -4.0, -5.0, -5.0, -4.0, -3.0, -5.0, -4.0, -4.0, -3.0, -4.0, -5.0, -3.0, -5.0, -4.0, -5.0, -5.0, -4.0, -3.0, -5.0, -4.0, -4.0, -3.0, -4.0, -5.0, -3.0, -5.0, -5.0, -2.0, -5.0, -5.0, -4.0, -1.0, -3.0, -3.0, -5.0, -5.0, 0.0, -3.0, -4.0, -4.0, -5.0, -4.0, -4.0, -5.0, -5.0, -5.0, -5.0, -5.0, -4.0, -5.0, -5.0, -4.0, -3.0, -3.0, -4.0, -5.0, -3.0, -3.0, -4.0, -4.0, -3.0, -5.0, -3.0, -3.0, -5.0, -5.0, -3.0, -5.0, -4.0, -2.0, -5.0, -5.0, -5.0, -4.0, -4.0, -3.0, -4.0, -5.0, -3.0])=-4.190871369294606

# 2025-10-29

No obseration boundary 8 cut, racket from diff - hack:
[97.0, 77.0, 76.0, 317.0, 145.0, 207.0, 211.0, 53.0, 101.0, 185.0, 297.0, 114.0, 77.0, 79.0, 97.0, 116.0, 135.0, 91.0, 77.0]

With obseration boundary 8 cut, racket from diff - hack:
[159.0, 51.0, 393.0, 90.0, 335.0, 58.0, 83.0, 63.0, 50.0, 115.0, 125.0, 189.0, 111.0, 115.0, 99.0, 32.0, 107.0, 128.0, 125.0]

Programmatically determining ball and rocket object position, programmatically operating  
[300.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0, 373.0, 306.0, 253.0, 383.0, 74.0]

# 2025-10-31

Programmatically determining ball and rocket object position, programmatically operating, fighting "cycling deadlocks"  

randomnes/reactivity=4/0:
truncated
scores = [273.0, 405.0, 405.0]
steps = [108000, 108000, 108000]
lives = [5, 5, 5]

randomnes/reactivity=4/1: (Best!!!!)
terminated
scores = [419.0, 423.0, 848.0]
steps = [10499, 12522, 34403]
lives = [0, 0, 0]

randomnes/reactivity=4/2: (Best!!!!)
terminated
scores = [416.0, 423.0, 851.0]
steps = [12024, 11941, 19433]
lives = [0, 0, 0]

randomnes/reactivity=4/3:
terminated
scores = [502.0, 493.0, 549.0]
steps = [16633, 14178, 17207]
lives = [0, 0, 0]

randomnes/reactivity=3/0:
truncated
scores = [238.0, 403.0, 403.0]
steps = [108000, 108000, 108000]
lives = [5, 3, 3]

randomnes/reactivity=3/1:
terminated
scores = [381.0, 422.0, 623.0]
steps = [14425, 11326, 15138]
lives = [0, 0, 0]

randomnes/reactivity=3/2:
terminated
scores = [427.0, 392.0, 359.0]
steps = [13936, 11541, 8965]
lives = [0, 0, 0]

randomnes/reactivity=3/3:
terminated
scores = [437.0, 400.0, 503.0]
steps = [12371, 10231, 19519]
lives = [0, 0, 0]

Programmatically set racket_row, rest is the same

randomnes/reactivity=4/0:
truncated
scores = [426.0, 405.0, 405.0, 405.0, 405.0, 405.0]
steps = [108000, 108000, 108000, 108000, 108000, 108000]
lives = [4, 5, 5, 5, 5, 5]

# TODO
TODO - re-run experiment with learing XY by manual - with TRUNCATED states *
TODO - learn to play in [rball_X, rocket_X] space - implement ball_x/rocket_x strategy learning
- + utility threshold on transitions
- + similarity threshold on similars
TODO - reporduce the "follow-the master" model by model-based player with generative randomness
TODO - fix crashes on start HACK: act = 2
TODO - avoid "cycling deadlocks" bugs
TODO - detect loops?

## Spaces - can be packed in series (transitions and N-transitions)):
Xball+Xrock+Act (Numeric) *
Xball+Xrock+Act (1-hot)
Xball+Xrock+Yrock+Act (Numeric)
Xball+Xrock+Yrock+Act (1-hot)
Xproj+Yproj+Act GS binary
Xproj+Yproj+Act GS binary / compact by 2
Xproj+Yproj+Act GS binary / compact by 4

* can add Rewared and Punish and Lives

## Playing modes (in any of the spaces above):
Programmatic
Programmatic->Model->PastExperiential
ProExperiential->Model->PastExperiential
